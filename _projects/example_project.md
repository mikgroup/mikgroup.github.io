---
title: Robot Learning from Human Feedback
description: |
  We develop algorithms that enable robots to efficiently learn from various forms of human feedback, including demonstrations, comparisons, and implicit signals like gaze and gestures.
people:
  - Erdem Bıyık
  - Yigit Korkmaz
layout: project
image: "/images/research/robot_learning.png"
last-updated: 2025-09-03
---

We develop robot learning algorithms that leverage various forms of data to enable AI agents to model the behaviors and goals of humans and other agents.

Our work focuses on learning from humans via multiple modes of information sources, including explicit forms such as human demonstrations and comparisons, and more implicit forms such as human gaze and gestures, to equip AI agents and robots with the capability to understand and align with humans' goals and preferences.

We also emphasize the importance of data-efficiency and expressiveness in learning and capturing humans' behaviors accurately.

## Key Contributions

- **Explainable Reinforcement Learning**: Developing interpretable RL algorithms that can explain their decisions to humans
- **Preference Learning**: Modeling beliefs over human preferences and tuning them with feedback
- **Active Learning**: Creating data-efficient algorithms for learning from comparisons
- **Multi-modal Learning**: Integrating various forms of human feedback into unified learning frameworks

## Applications

Our algorithms have been applied to:
- Personal robotics systems
- Assistive exoskeletons for people with paralysis
- Autonomous vehicle systems
- Multi-agent coordination

